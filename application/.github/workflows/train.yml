name: Continuous Training and Deployment

on:
  schedule:
    - cron: "0 0 * * *" # Run every day at midnight
  workflow_dispatch: # Run manually
  push:
    branches:
      - master

jobs:
  train_and_deploy:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install dvc[all]
          pip install -r requirements.txt

      # Step 4: Configure Google Drive credentials
      - name: Configure Google Drive credentials
        env:
          GDRIVE_SERVICE_ACCOUNT_BASE64: ${{ secrets.GDRIVE_SERVICE_ACCOUNT_BASE64 }}
        run: |
          echo "${{ secrets.GDRIVE_SERVICE_ACCOUNT_BASE64 }}" | base64 --decode > google_services.json

      # Step 5: Configure DVC Remote
      - name: Configure DVC Remote
        run: |
          dvc remote modify storage gdrive_use_service_account true
          dvc remote modify --local storage gdrive_service_account_json_file_path google_services.json

      # Step 6: Pull dataset from DVC remote
      - name: Pull dataset
        run: dvc pull

      # Step 7: Run DVC-related tasks locally (Optional)
      - name: Run local data preprocessing
        run: |
          python src/data_ingestion/youtube_comments/main.py
          python src/scripts/main.py
          dvc add data/train.csv
          git add data/train.csv.dvc
          git commit -m "Update dataset"
          dvc push

      # Step 8: Deploy to server
      - name: Deploy to server
        uses: appleboy/ssh-action@v0.1.9
        with:
          host: ${{ secrets.SERVER_IP }}
          username: ${{ secrets.SERVER_USER }}
          key: ${{ secrets.SERVER_SSH_KEY }}
          script: |
            set -e
            # Navigate to the application directory
            cd docker/experiments/application

            # Pull the latest changes
            git pull origin master

            # Rebuild and redeploy the Docker services
            docker compose up -d --build

            # Run data preprocessing and training inside the container
            docker exec -it flask_app_1 bash -c "
              dvc pull &&
              python src/data_ingestion/youtube_comments/main.py &&
              python src/scripts/main.py &&
              python src/models/train_model.py &&
              dvc add data/train.csv &&
              git add data/train.csv.dvc &&
              git commit -m 'Update dataset' &&
              dvc push
            "
